{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算香农熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator\n",
    "# import treePlotter 绘制决策树的模块\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet) #获得样本数量\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1] #当前样本的类别\n",
    "        if currentLabel not in labelCounts.key(): labelCounts[currentLable] = 0\n",
    "        labelCounts[currentLabel] += 1 # 统计每个类目的次数，保存为字典\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries #每种类别出现的频率\n",
    "        shannonEnt -= pro*log(pro,2)               #按香农公式计算香农熵\n",
    "    return shannonEnt\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tips:什么是香农熵\n",
    "    熵表示系统中的稳定的状态，如果一个系统中的粒子存在可能比较多的位置，那这个系统具有比较高的熵值，在熵和概率的关系中，拥有越多排列的可能性，则熵值越大。\n",
    "    而熵和信息论的关系是，对于熵值高的系统，需要更多的信息，再能获得整个系统的状态。\n",
    "    应用在划分数据集上，划分数据集之前之后信息发生的变化称为信息增益，计算出每个特征的信息增益，就可以根据信息增益划分特征，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet,axis,value):\n",
    "    retDataSet = []   #初始化分割后的样本集为空\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:                  # axis表示选取的特征列索引，value代表特征的某一取值\n",
    "            reducedFeatVec = featVec[:axis]         # 取出特征列左侧的数据\n",
    "            reducedFeatVec.extend(featVec[axis+1:]) # 合并特征列右侧的数据\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "            \"\"\"\n",
    "            返回值为一样本子集，样本数量（行数）与axis指向特征取值为value的样本子集（记为C）相同\n",
    "            该样本子集是在上述样本子集C的基础上剔除掉axis指向特征取值为value的一列\n",
    "            （exg：贷款申请样本集中，axis指向年龄，value代表青年，返回值即为包含青年的样本子集中\n",
    "            剔除掉青年所在列后的样本集）\n",
    "            \"\"\" \n",
    "    return retDataSet            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择最佳分割特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choodeBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1     # 特征数量\n",
    "    beseEntropy = calcShannonEnt(dataSet) # 基础熵为样本集本身的香农熵\n",
    "    bastInfoGain = 0.0;bastFeature = -1   # 初始化最大信息增益为0；最佳特征索引为-1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet] # 取出第i个特征列数据\n",
    "        uniqueVals = set(featList)        # 第i个特征的取值范围\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet,i,value) # 利用当前特征的每个取值分割样本集\n",
    "            prob = len(subDataSet)/float(len(dataSet)) # 当前样本子集在全体样本集中的占比\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet) # 当前样本子集的香农熵\n",
    "            infoGain = baseEntropy - newEntropy # 计算信息增益\n",
    "        if (infoGain > bestInfoGain):       # 与历史最大信息增益比较\n",
    "            bestInfoGain = infoGain         # 更新最大信息增益\n",
    "            bestFeature = i                 # 更新最佳特征索引\n",
    "    return bestFeature                      # 返回最佳特征列索引\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从类别列表中计算出现次数最多的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if voto not in classCount.key():classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    #operator.itemgetter用于获取对象的哪些维的数据\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True) \n",
    "    return sortedCladdCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sorted函数：对List、Dict进行排序\n",
    "    方法1.用List的成员函数sort进行排序，在本地进行排序，不返回副本\n",
    "    方法2.用built-in函数sorted进行排序（从2.4开始）\n",
    "    sorted(iterable, cmp=None, key=None, reverse=False) #iterable是一个迭代器\n",
    "    L.sort(cmp=None, key=None, reverse=False) \n",
    "    参数说明：\n",
    "        ·cmp：用于比较的函数，比较什么由key决定;\n",
    "        ·key：用列表元素的某个属性或函数进行作为关键字，有默认值，迭代集合中的一项;\n",
    "        ·reverse：排序规则. reverse = True  降序 或者 reverse = False 升序，有默认值。\n",
    "        ·返回值：是一个经过排序的可迭代类型，与iterable一样。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet,labels):\n",
    "    classList = [example[-1] for example in dataSet]  #取出类别类\n",
    "    if classList.count(classList[0]) == len(classList): #只有一个类别的时候停止分类，返回当前类别\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1: #当没有更多特征时停止分裂，返回实例中数量最多的类\n",
    "        return majorityCnt(classList)\n",
    "    \n",
    "    bestFeat = chooseBestFeatureToSplist(dataSet)  #最佳特征对应的序号\n",
    "    bestFeatLabel = labels[bestFeat]              # 最佳特征名称/说明\n",
    "    myTree = {bestFeatLabel:{}}  # 嵌套创建树\n",
    "    del(labels[bestFeat])        # 从特征名中删除掉已经选为最佳特征的\n",
    "    featValues = [example[bestFeat] for example in dataSet]   # 最佳特征数据列\n",
    "    uniqueVals = set(featValues) # 最佳特征列的取值集合\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]    # 拷贝特征名， 避免搞乱原有值\n",
    "        '''\n",
    "        在当前最佳特征为节点前的下方递归构构建树\n",
    "        '''\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet,bestFeat,value),subLabels)\n",
    "    return myTree\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例：决策树处理隐形眼镜问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lenses.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-544ebc24bd66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lenses.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlenses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlensesLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prescript'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'astigmatic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tearRate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlensesTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlensesLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlensesTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lenses.txt'"
     ]
    }
   ],
   "source": [
    "fr = open('lenses.txt')\n",
    "lenses = [inst.strip().split('\\t') for inst in fr.readlines()]\n",
    "lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "lensesTree = createTree(lenses,lensesLabels)\n",
    "lensesTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制决策树\n",
    "treePlotter.createPlot(lensesTree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
